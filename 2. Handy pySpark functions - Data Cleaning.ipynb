{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import spark_utils as sut\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "import pyspark.sql.functions as F\n",
    "spark = sut.get_spark_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook demos the custom PySpark functions discussed in [Speed up Your ML Projects With Spark -- Handy Custom {pySpark} Functions (II)](https://medium.com/@menawang/speed-up-your-ml-projects-with-spark-675c5e269d13) published on [Towards AI](https://pub.towardsai.net/). \n",
    "\n",
    "The revelant functions were saved in [spark_utils.py](spark_utils.py) and imported into this notebook for demo by `import spark_utils as sut`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Spark DataFrame\n",
    "\n",
    "You probably guessed it by looking at the dummy data below. In this article, we will discuss functions to handle tricky dates and messy numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---------+----------+--------------------+--------------+------+\n",
      "|ID1|ID2|   date_1|    date_2|              date_3|   description|amount|\n",
      "+---+---+---------+----------+--------------------+--------------+------+\n",
      "|  A|101|15Jan2024|2024/01/15|2024-01-15 12:01:...|TAS-individual|110000|\n",
      "|  A|101|15Jul2023|2023/07/15|2023-07-15 09:07:...|QLD-individual|130000|\n",
      "|  B|102|20Aug2023|2023/08/20|2023-08-20 10:08:...|  NSW-business|130000|\n",
      "|  B|102|19Feb2024|2024/02/19|2024-02-19 13:02:...|  NSW-business|140000|\n",
      "|  C|103|15Jan2024|2024/01/15|2024-01-15 14:01:...|  QLD-business|115000|\n",
      "|  C|103|25Oct2023|2023/10/25|2023-10-25 11:10:...|  VIC-business| 95000|\n",
      "+---+---+---------+----------+--------------------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date, col\n",
    "from typing import List\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"SparkDemo\").getOrCreate()\n",
    "\n",
    "# Sample data with 'yyyy/MM/dd' date format\n",
    "data = [\n",
    "    (\"A\", \"101\", \"15Jul2023\", \"2023/07/15\", \"2023-07-15 09:07:33.0\", \"QLD-individual\", \"130000\"),\n",
    "    (\"B\", \"102\", \"20Aug2023\", \"2023/08/20\", \"2023-08-20 10:08:45.0\", \"NSW-business\", \"130000\"),\n",
    "    (\"C\", \"103\", \"25Oct2023\", \"2023/10/25\", \"2023-10-25 11:10:50.0\", \"VIC-business\", \"95000\"),\n",
    "    (\"A\", \"101\", \"15Jan2024\", \"2024/01/15\", \"2024-01-15 12:01:30.0\", \"TAS-individual\", \"110000\"),\n",
    "    (\"B\", \"102\", \"19Feb2024\", \"2024/02/19\", \"2024-02-19 13:02:40.0\", \"NSW-business\", \"140000\"),\n",
    "    (\"C\", \"103\", \"15Jan2024\", \"2024/01/15\", \"2024-01-15 14:01:55.0\", \"QLD-business\", \"115000\")\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, [\"ID1\", \"ID2\", \"date_1\", \"date_2\", \"date_3\", \"description\", \"amount\"])\n",
    "\n",
    "df = df.orderBy('ID1','ID2')\n",
    "\n",
    "# Show DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID1: string (nullable = true)\n",
      " |-- ID2: string (nullable = true)\n",
      " |-- amount: string (nullable = true)\n",
      " |-- date_1: string (nullable = true)\n",
      " |-- date_2: string (nullable = true)\n",
      " |-- date_3: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sut.print_schema_alphabetically(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transform date cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----------+----------+--------------------+--------------+------+\n",
      "|ID1|ID2|    date_1|    date_2|              date_3|   description|amount|\n",
      "+---+---+----------+----------+--------------------+--------------+------+\n",
      "|  A|101|2023-07-15|2023/07/15|2023-07-15 09:07:...|QLD-individual|130000|\n",
      "|  A|101|2024-01-15|2024/01/15|2024-01-15 12:01:...|TAS-individual|110000|\n",
      "|  B|102|2024-02-19|2024/02/19|2024-02-19 13:02:...|  NSW-business|140000|\n",
      "|  B|102|2023-08-20|2023/08/20|2023-08-20 10:08:...|  NSW-business|130000|\n",
      "|  C|103|2023-10-25|2023/10/25|2023-10-25 11:10:...|  VIC-business| 95000|\n",
      "|  C|103|2024-01-15|2024/01/15|2024-01-15 14:01:...|  QLD-business|115000|\n",
      "+---+---+----------+----------+--------------------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sut.transform_date_cols(df,['date_1'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----------+----------+--------------------+--------------+------+\n",
      "|ID1|ID2|    date_1|    date_2|              date_3|   description|amount|\n",
      "+---+---+----------+----------+--------------------+--------------+------+\n",
      "|  A|101|2023-07-15|2023-07-15|2023-07-15 09:07:...|QLD-individual|130000|\n",
      "|  A|101|2024-01-15|2024-01-15|2024-01-15 12:01:...|TAS-individual|110000|\n",
      "|  B|102|2023-08-20|2023-08-20|2023-08-20 10:08:...|  NSW-business|130000|\n",
      "|  B|102|2024-02-19|2024-02-19|2024-02-19 13:02:...|  NSW-business|140000|\n",
      "|  C|103|2024-01-15|2024-01-15|2024-01-15 14:01:...|  QLD-business|115000|\n",
      "|  C|103|2023-10-25|2023-10-25|2023-10-25 11:10:...|  VIC-business| 95000|\n",
      "+---+---+----------+----------+--------------------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sut.transform_date_cols(df,['date_2'], \n",
    "                             str_date_format='yyyy/MM/dd')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----------+----------+----------+--------------+------+\n",
      "|ID1|ID2|    date_1|    date_2|    date_3|   description|amount|\n",
      "+---+---+----------+----------+----------+--------------+------+\n",
      "|  A|101|2024-01-15|2024-01-15|2024-01-15|TAS-individual|110000|\n",
      "|  A|101|2023-07-15|2023-07-15|2023-07-15|QLD-individual|130000|\n",
      "|  B|102|2023-08-20|2023-08-20|2023-08-20|  NSW-business|130000|\n",
      "|  B|102|2024-02-19|2024-02-19|2024-02-19|  NSW-business|140000|\n",
      "|  C|103|2023-10-25|2023-10-25|2023-10-25|  VIC-business| 95000|\n",
      "|  C|103|2024-01-15|2024-01-15|2024-01-15|  QLD-business|115000|\n",
      "+---+---+----------+----------+----------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sut.transform_date_cols(df,['date_3'], \n",
    "                             str_date_format='yyyy-MM-dd HH:mm:ss.S')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_1: date (nullable = true)\n",
      " |-- date_2: date (nullable = true)\n",
      " |-- date_3: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sut.print_schema_alphabetically(df.select(['date_1','date_2', 'date_3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----------+----------+----------+--------------+------+\n",
      "|ID1|ID2|    date_1|    date_2|    date_3|   description|amount|\n",
      "+---+---+----------+----------+----------+--------------+------+\n",
      "|  A|101|2024-01-15|2024-01-15|2024-01-15|TAS-individual|110000|\n",
      "|  A|101|2023-07-15|2023-07-15|2023-07-15|QLD-individual|130000|\n",
      "|  B|102|2023-08-20|2023-08-20|2023-08-20|  NSW-business|130000|\n",
      "|  B|102|2024-02-19|2024-02-19|2024-02-19|  NSW-business|140000|\n",
      "|  C|103|2024-01-15|2024-01-15|2024-01-15|  QLD-business|115000|\n",
      "|  C|103|2023-10-25|2023-10-25|2023-10-25|  VIC-business| 95000|\n",
      "+---+---+----------+----------+----------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test function on a col that is already in date format\n",
    "check = sut.transform_date_cols(df,['date_2'])\n",
    "check.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----------+----------+----------+--------------+------+\n",
      "|ID1|ID2|    date_1|    date_2|    date_3|   description|amount|\n",
      "+---+---+----------+----------+----------+--------------+------+\n",
      "|  A|101|2023-07-15|2023-07-15|2023-07-15|QLD-individual|130000|\n",
      "|  A|101|2024-01-15|2024-01-15|2024-01-15|TAS-individual|110000|\n",
      "|  B|102|2023-08-20|2023-08-20|2023-08-20|  NSW-business|130000|\n",
      "|  C|103|2023-10-25|2023-10-25|2023-10-25|  VIC-business| 95000|\n",
      "|  C|103|2024-01-15|2024-01-15|2024-01-15|  QLD-business|115000|\n",
      "+---+---+----------+----------+----------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check = sut.filter_by_date(df, 'date_2', \n",
    "                           min_date=\"2023-07-01\", \n",
    "                           max_date=\"2024-02-05\",\n",
    "                           original_date_format='yyyy/MM/dd')\n",
    "check.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get distinct values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.date(2023, 7, 15),\n",
       " datetime.date(2023, 8, 20),\n",
       " datetime.date(2023, 10, 25),\n",
       " datetime.date(2024, 1, 15)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sut.get_distinct_values(check, 'date_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## top_rows_for_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----------+----------+----------+--------------+------+\n",
      "|ID1|ID2|    date_1|    date_2|    date_3|   description|amount|\n",
      "+---+---+----------+----------+----------+--------------+------+\n",
      "|  A|101|2024-01-15|2024-01-15|2024-01-15|TAS-individual|110000|\n",
      "|  B|102|2024-02-19|2024-02-19|2024-02-19|  NSW-business|140000|\n",
      "|  C|103|2024-01-15|2024-01-15|2024-01-15|  QLD-business|115000|\n",
      "+---+---+----------+----------+----------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the latest record for each ID1 & ID2 combination\n",
    "check = sut.top_rows_for_ids(df,['ID1','ID2'], \n",
    "                            value_field = 'date_1', \n",
    "                            ascending = False)\n",
    "check.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----------+----------+----------+--------------+------+\n",
      "|ID1|ID2|    date_1|    date_2|    date_3|   description|amount|\n",
      "+---+---+----------+----------+----------+--------------+------+\n",
      "|  A|101|2023-07-15|2023-07-15|2023-07-15|QLD-individual|130000|\n",
      "|  B|102|2024-02-19|2024-02-19|2024-02-19|  NSW-business|140000|\n",
      "|  C|103|2023-10-25|2023-10-25|2023-10-25|  VIC-business| 95000|\n",
      "+---+---+----------+----------+----------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the record with the highest amount for each ID\n",
    "check = sut.top_rows_for_ids(df,['ID1','ID2'], \n",
    "                            value_field = 'amount', \n",
    "                            ascending = False)\n",
    "check.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean dollar values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----------+----------+----------+--------------+--------+\n",
      "|ID1|ID2|    date_1|    date_2|    date_3|   description|  amount|\n",
      "+---+---+----------+----------+----------+--------------+--------+\n",
      "|  A|101|2024-01-15|2024-01-15|2024-01-15|TAS-individual|110000.0|\n",
      "|  A|101|2023-07-15|2023-07-15|2023-07-15|QLD-individual|130000.0|\n",
      "|  B|102|2024-02-19|2024-02-19|2024-02-19|  NSW-business|140000.0|\n",
      "|  B|102|2023-08-20|2023-08-20|2023-08-20|  NSW-business|130000.0|\n",
      "|  C|103|2024-01-15|2024-01-15|2024-01-15|  QLD-business|115000.0|\n",
      "|  C|103|2023-10-25|2023-10-25|2023-10-25|  VIC-business| 95000.0|\n",
      "+---+---+----------+----------+----------+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sut.clean_dollar_cols(df,['amount'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter df by strings\n",
    "\n",
    "In the example below, we can use the function to find `individual` records in either `QLD` or `NSW` in two steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Step 1: Filter for either states\n",
      "+---+---+----------+----------+----------+--------------+--------+\n",
      "|ID1|ID2|    date_1|    date_2|    date_3|   description|  amount|\n",
      "+---+---+----------+----------+----------+--------------+--------+\n",
      "|  A|101|2023-07-15|2023-07-15|2023-07-15|QLD-individual|130000.0|\n",
      "|  B|102|2023-08-20|2023-08-20|2023-08-20|  NSW-business|130000.0|\n",
      "|  B|102|2024-02-19|2024-02-19|2024-02-19|  NSW-business|140000.0|\n",
      "|  C|103|2024-01-15|2024-01-15|2024-01-15|  QLD-business|115000.0|\n",
      "+---+---+----------+----------+----------+--------------+--------+\n",
      "\n",
      "---- Step2: Find 'individual' records only\n",
      "+---+---+----------+----------+----------+--------------+--------+\n",
      "|ID1|ID2|    date_1|    date_2|    date_3|   description|  amount|\n",
      "+---+---+----------+----------+----------+--------------+--------+\n",
      "|  A|101|2023-07-15|2023-07-15|2023-07-15|QLD-individual|130000.0|\n",
      "+---+---+----------+----------+----------+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find `individual` records in either `QLD` or `NSW` in two steps.\n",
    "print(\"---- Step 1: Filter for either states\")\n",
    "search_strings = ['QLD', \"NSW\"]\n",
    "state_filtered = sut.filter_df_by_strings(df, 'description', search_strings)\n",
    "state_filtered.show()\n",
    "print(\"---- Step2: Find 'individual' records only\")\n",
    "final = sut.filter_df_by_strings(state_filtered, 'description', ['individual'])\n",
    "final.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
