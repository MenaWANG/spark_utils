{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import spark_utils as sut\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+---+-------------+\n",
      "|ID1|ID2|   Name|Age|         City|\n",
      "+---+---+-------+---+-------------+\n",
      "|101|  A|  Alice| 25|     New York|\n",
      "|102|  B|    Bob| 30|  Los Angeles|\n",
      "|103|  A|  Alice| 26|San Francisco|\n",
      "|104|  C|Charlie| 35|      Chicago|\n",
      "|105|  B|    Bob| 30|  Los Angeles|\n",
      "|101|  A|  Alice| 25|           NY|\n",
      "+---+---+-------+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkFunctionDemo\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define schema for the DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"ID1\", IntegerType(), True),\n",
    "    StructField(\"ID2\", StringType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"City\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Sample data with duplicates based on ID1 and ID2\n",
    "data = [\n",
    "    (101, 'A', 'Alice', 25, 'New York'),\n",
    "    (102, 'B', 'Bob', 30, 'Los Angeles'),\n",
    "    (103, 'A', 'Alice', 26, 'San Francisco'),\n",
    "    (104, 'C', 'Charlie', 35, 'Chicago'),\n",
    "    (105, 'B', 'Bob', 30, 'Los Angeles'),\n",
    "    (101, 'A', 'Alice', 25, 'NY')  \n",
    "]\n",
    "\n",
    "# Create Spark DataFrame directly\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# Show the Spark DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom pySpark functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 6\n",
      "Number of columns: 5\n"
     ]
    }
   ],
   "source": [
    "sut.shape(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print schema alphabetically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- ID1: integer (nullable = true)\n",
      " |-- ID2: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sut.print_schema_alphabetically(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## verify primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total row count after filtering out missings: 6\n",
      "Unique row count after filtering out missings: 5\n",
      "The column(s) ID1, ID2 does not form a primary key.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_cols = ['ID1', 'ID2']\n",
    "sut.is_primary_key(df, id_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total row count after filtering out missings: 6\n",
      "Unique row count after filtering out missings: 5\n",
      "The column(s) ID1, ID2 does not form a primary key.\n",
      "+-----+---+---+-----+---+--------+\n",
      "|count|ID1|ID2| Name|Age|    City|\n",
      "+-----+---+---+-----+---+--------+\n",
      "|    2|101|  A|Alice| 25|New York|\n",
      "|    2|101|  A|Alice| 25|      NY|\n",
      "+-----+---+---+-----+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if sut.is_primary_key(df, id_cols) == False:\n",
    "    dups = sut.find_duplicates(df, id_cols)\n",
    "    dups.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## identify columns responsible for dups\n",
    "\n",
    "With our simple dummy table, we can easily tell that the dups are due to `City` column. But when you have very wide table and many dups, this task becomes much trickier. The `cols_responsible_for_id_dups` function comes in rescue by summarizing the `difference_counts` for each column based on the primary key(s) provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total row count after filtering out missings: 6\n",
      "Unique row count after filtering out missings: 5\n",
      "The column(s) ID1, ID2 does not form a primary key.\n",
      "+--------+-----------------+\n",
      "|col_name|difference_counts|\n",
      "+--------+-----------------+\n",
      "|    City|                1|\n",
      "|    Name|                0|\n",
      "|     Age|                0|\n",
      "+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if sut.is_primary_key(df, id_cols) == False:\n",
    "    dup_cols = sut.cols_responsible_for_id_dups(df, id_cols)\n",
    "    dup_cols.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
