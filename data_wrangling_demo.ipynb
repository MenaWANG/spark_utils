{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import spark_utils as sut\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---------+----------+----+--------+\n",
      "|ID1|ID2|   date_1|    date_2|city|  income|\n",
      "+---+---+---------+----------+----+--------+\n",
      "|  A|101|15Jul2023|2023/07/15| QLD|        |\n",
      "|  B|102|20Aug2023|2023/08/20| NSW|  130000|\n",
      "|  C|103|25Oct2023|2023/10/25| VIC|  95,000|\n",
      "|  A|101|15Jan2024|2024/01/15| NSW|$110,000|\n",
      "|  B|102|19Feb2024|2024/02/19| NSW|$140,000|\n",
      "+---+---+---------+----------+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook demos the custom PySpark functions discussed in [Speed up Your ML Projects With Spark -- Handy Custom {pySpark} Functions (II)]() published on Towards AI. \n",
    "\n",
    "The revelant functions were saved in [spark_utils.py](spark_utils.py) and imported into this notebook for demo by `import spark_utils as sut`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---------+----------+----+--------+\n",
      "|ID1|ID2|   date_1|    date_2|city|  income|\n",
      "+---+---+---------+----------+----+--------+\n",
      "|  A|101|15Jul2023|2023/07/15| QLD|        |\n",
      "|  A|101|15Jan2024|2024/01/15| TAS|$110,000|\n",
      "|  B|102|20Aug2023|2023/08/20| NSW|  130000|\n",
      "|  B|102|19Feb2024|2024/02/19| NSW|$140,000|\n",
      "|  C|103|25Oct2023|2023/10/25| VIC|  95,000|\n",
      "+---+---+---------+----------+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date, col\n",
    "from typing import List\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"SparkDemo\").getOrCreate()\n",
    "\n",
    "# Sample data with 'yyyy/MM/dd' date format\n",
    "data = [\n",
    "    (\"A\", \"101\", \"15Jul2023\", \"2023/07/15\", \"QLD\", \"\"),\n",
    "    (\"B\", \"102\", \"20Aug2023\", \"2023/08/20\", \"NSW\", \"130000\"),\n",
    "    (\"C\", \"103\", \"25Oct2023\", \"2023/10/25\", \"VIC\", \"95,000\"),\n",
    "    (\"A\", \"101\", \"15Jan2024\", \"2024/01/15\", \"TAS\", \"$110,000\"),\n",
    "    (\"B\", \"102\", \"19Feb2024\", \"2024/02/19\", \"NSW\", \"$140,000\"),\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, [\"ID1\", \"ID2\", \"date_1\", \"date_2\", \"city\", \"income\"])\n",
    "\n",
    "df = df.orderBy('ID1','ID2')\n",
    "\n",
    "# Show DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter df by strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_strings = ['QLD', \"NSW\"]\n",
    "check = sut.filter_df_by_strings(df, 'city', search_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---------+----------+----+--------+\n",
      "|ID1|ID2|   date_1|    date_2|city|  income|\n",
      "+---+---+---------+----------+----+--------+\n",
      "|  A|101|15Jul2023|2023/07/15| QLD|        |\n",
      "|  B|102|20Aug2023|2023/08/20| NSW|  130000|\n",
      "|  B|102|19Feb2024|2024/02/19| NSW|$140,000|\n",
      "+---+---+---------+----------+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
